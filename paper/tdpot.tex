
\documentclass[a4paper,UKenglish,cleveref, autoref, thm-restate]{lipics-v2021}
%This is a template for producing LIPIcs articles. 
%See lipics-v2021-authors-guidelines.pdf for further information.
%for A4 paper format use option "a4paper", for US-letter use option "letterpaper"
%for british hyphenation rules use option "UKenglish", for american hyphenation rules use option "USenglish"
%for section-numbered lemmas etc., use "numberwithinsect"
%for enabling cleveref support, use "cleveref"
%for enabling autoref support, use "autoref"
%for anonymousing the authors (e.g. for double-blind review), add "anonymous"
%for enabling thm-restate support, use "thm-restate"
%for enabling a two-column layout for the author/affilation part (only applicable for > 6 authors), use "authorcolumns"
%for producing a PDF according the PDF/A standard, add "pdfa"

%\pdfoutput=1 %uncomment to ensure pdflatex processing (mandatatory e.g. to submit to arXiv)
%\hideLIPIcs  %uncomment to remove references to LIPIcs series (logo, DOI, ...), e.g. when preparing a pre-final version to be uploaded to arXiv or another public repository

%\graphicspath{{./graphics/}}%helpful if your graphic files are in another directory

\bibliographystyle{plainurl}% the mandatory bibstyle

% fast and exact
\title{Combining Predicted and Live-Traffic with Time-Dependent A* Potentials} %TODO Please add

%\titlerunning{Dummy short title} %TODO optional, please use if title is longer than one line

% \author{Jane {Open Access}}{Dummy University Computing Laboratory, [optional: Address], Country \and My second affiliation, Country \and \url{http://www.myhomepage.edu} }{johnqpublic@dummyuni.org}{https://orcid.org/0000-0002-1825-0097}{(Optional) author-specific funding acknowledgements}%TODO mandatory, please use full name; only 1 author per \author macro; first two parameters are mandatory, other parameters can be empty. Please provide at least the name of the affiliation and the country. The full address is optional. Use additional curly braces to indicate the correct name splitting when the last name consists of multiple name parts.

\author{Nils Werner}{Karlsruhe Institute of Technology, Germany}{}{}{}
\author{Tim Zeitz}{Karlsruhe Institute of Technology, Germany}{tim.zeitz@kit.edu}{https://orcid.org/0000-0003-4746-3582}{}

\authorrunning{N. Werner and T. Zeitz} %TODO mandatory. First: Use abbreviated first/middle names. Second (only in severe cases): Use first author plus 'et al.'

\Copyright{Nils Werner and Tim Zeitz} %TODO mandatory, please use full first names. LIPIcs license is "CC-BY";  http://creativecommons.org/licenses/by/3.0/

% \ccsdesc[100]{\textcolor{red}{Replace ccsdesc macro with valid one}} %TODO mandatory: Please choose ACM 2012 classifications from https://dl.acm.org/ccs/ccs_flat.cfm
\ccsdesc[500]{Theory of computation~Shortest paths}
\ccsdesc[300]{Mathematics of computing~Graph algorithms}
\ccsdesc[500]{Applied computing~Transportation}

\keywords{realistic road networks, route planning, shortest paths, traffic-aware routing, live traffic} %TODO mandatory; please add comma-separated list of keywords

% \category{} %optional, e.g. invited paper

% \relatedversion{} %optional, e.g. full version hosted on arXiv, HAL, or other respository/website
%\relatedversiondetails[linktext={opt. text shown instead of the URL}, cite=DBLP:books/mk/GrayR93]{Classification (e.g. Full Version, Extended Version, Previous Version}{URL to related version} %linktext and cite are optional

%\supplement{}%optional, e.g. related research data, source code, ... hosted on a repository like zenodo, figshare, GitHub, ...
%\supplementdetails[linktext={opt. text shown instead of the URL}, cite=DBLP:books/mk/GrayR93, subcategory={Description, Subcategory}, swhid={Software Heritage Identifier}]{General Classification (e.g. Software, Dataset, Model, ...)}{URL to related version} %linktext, cite, and subcategory are optional

%\funding{(Optional) general funding statement \dots}%optional, to capture a funding statement, which applies to all authors. Please enter author specific funding statements as fifth argument of the \author macro.

\acknowledgements{I want to thank \dots}%optional

%\nolinenumbers %uncomment to disable line numbering



%Editor-only macros:: begin (do not touch as author)%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\EventEditors{John Q. Open and Joan R. Access}
\EventNoEds{2}
\EventLongTitle{42nd Conference on Very Important Topics (CVIT 2016)}
\EventShortTitle{CVIT 2016}
\EventAcronym{CVIT}
\EventYear{2016}
\EventDate{December 24--27, 2016}
\EventLocation{Little Whinging, United Kingdom}
\EventLogo{}
\SeriesVolume{42}
\ArticleNo{23}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand*{\pred}{f}
\newcommand*{\comb}{f^*}
\newcommand*{\opttt}{\mathcal{T}}
\newcommand*{\dist}{\mathcal{D}}
\newcommand*{\lb}{\mathcal{L}}

\newcommand*{\tdep}{\tau^{\operatorname{dep}}}
\newcommand*{\tmax}{\tau^{\max}}

\newcommand*{\gchu}{G^{\uparrow}}
\newcommand*{\gchd}{\overleftarrow{G^{\downarrow}}}

\usepackage[algo2e,vlined]{algorithm2e}
\usepackage{booktabs}

\begin{document}

\maketitle

%TODO mandatory: add short abstract of the document
\begin{abstract}
Lorem ipsum dolor sit amet, consectetur adipiscing elit. Praesent convallis orci arcu, eu mollis dolor. Aliquam eleifend suscipit lacinia. Maecenas quam mi, porta ut lacinia sed, convallis ac dui. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Suspendisse potenti. 
\end{abstract}

\newpage

\section{Introduction}

An important feature of modern routing applications and navigation devices is the integration of traffic information into routing decisions.
The more comprehensive the considered traffic information, the better the suggested routes, the more accurate the predicted arrival times and ultimately, the more satisfied the users.
For routing, we can distinguish between two aspects of traffic:
On the one hand, there are \emph{predictable} traffic flows.
For example certain highways will consistently have traffic jams on weekday afternoons due to commuters driving home.
On the other hand, unexpected events such as accidents may also have significant influence on the \emph{current} traffic situation.
While it may be sufficient to focus on the current traffic situation to answer short-range routing request, mid- and long-range queries require taking both types of traffic into account.
% example with traffic jam now and in 300km?
We therefore aim to provide routing algorithms which incorporate \emph{combined} predicted and live traffic information.

A common approach for routing in road networks is to model the network as a directed graph where intersections become vertices and road segments become edges.
With edge weights representing travel times, routing requests can be answered by solving the classical shortest path problem.
When considering predicted traffic, edge weights can be modeled as functions of the daytime, which is commonly referred to as \emph{time-dependent routing}.
Dijkstra's algorithm can be used to solve these problems exactly and, at least from a theoretical perspective, efficiently~\cite{d-ntpcg-59}.
However, on the continental-sized road networks used in modern routing applications, it may take seconds to answer mid- or long-range queries which is too slow for most practical applications.
We therefore study algorithms to compute shortest paths significantly faster than Dijkstra's algorithm while retaining exactness.

In this work, we utilize the A* algorithm~\cite{hnr-afbhd-68} for this.
A* can be seen as an extension of Dijkstra's algorithm.
Dijkstra's algorithm explores all vertices closer to the origin than the destination by utilizing a queue where vertices are ordered by their distance from the origin vertex.
A* changes the order in which vertices are visited by adding an estimate of the remaining distance to the queue key, sometimes called \emph{heuristic} or \emph{potential}.
The performance depends on the tightness of these estimates.
The algorithmic core idea of this work are time-dependent potential functions, i.e.\ we obtain tighter estimates by taking the time a vertex is visited into account.

\subsection{Related Work}

Efficient and exact route planning in road networks has received a significant amount of research effort in the past decade.
Since a comprehensive overview is beyond the scope of this paper, we refer to~\cite{bdgmpsww-rptn-16} for an overview.
An approach that has proven quite effective is to exploit that road networks rarely change and usually many queries have to be answered on the same network.
Thus, these queries can be accelerated by computing auxiliary data in an off-line preprocessing phase.

A popular technique following this approach is \emph{Contraction Hierarchies} (CH)~\cite{gssv-erlrn-12}.
During the preprocessing vertices are heuristically ranked by importance (more important vertices are part of more shortest paths).
Shortcut edges are inserted to skip over unimportant vertices.
This allows for a very fast query where only few vertices are explored.
On typical continental-sized benchmark instances, queries take well below a millisecond.
\emph{Multi-Level Dijkstra} (MLD)~\cite{swz-umlgt-02} is a similar approach which also utilizes shortcut edges but inserts them based on a multi-level partitioning.
It achieves slightly slower query times around a millisecond.
MLD is popular for being the first algorithm to support the concept of \emph{customizability} and therefore sometimes also referred by \emph{Customizable Route Planning} (CRP)~\cite{dgpw-crprn-13}.
The \emph{customization} is a second faster preprocessing phase which allows integrating arbitrary weight functions (or live-traffic updates the current weights) into the auxiliary data without rerunning the whole slow first preprocessing phase.
The MLD customization takes a couple of seconds which allows running it every minute.
CH was later generalized to support customizability as well which resulted in Customizable Contraction Hierarchies (CCH)~\cite{dsw-cch-15}.

Both CH and MLD have been extended to time-dependent routing.
However, dealing with weight functions instead of scalar weights makes the preprocessing much harder and leads to difficult trade-offs.
TCH~\cite{bgsv-mtdtt-13} has fast queries but a very expensive preprocessing phase (may take hours) and may produce prohibitive amounts of auxiliary data (> 100\,GB).
% TODO 3-phase not introduced
TD-CRP~\cite{bdpw-dtdrp-16} (the MLD variant) still follows a 3-phase approach and has a relatively fast customization phase.
However, this is only possible by giving up exactness.
Also, TD-CRP does not support path unpacking.
CATCHUp~\cite{swz-sfert-21} adapts CCH to the time-dependent setting and has fast and exact queries with significantly reduced memory consumption.
While it has a customization phase, running it takes significantly longer than a traditional CCH or CRP customization.
On the benchmark graphs used in this paper, a CATCHUp customization may even take hours, which is too slow for a live-traffic updates setting.
% TDS?, (Shark?)

A* has also been utilized in speed-up techniques for routing in road networks.
With ALT~\cite{gh-cspas-05,gw-cppsp-05}, a few landmark vertices are selected during preprocessing.
From and to these vertices distances to all other vertices are precomputed.
During queries, these distances are combined with the triangle inequality to obtain distance estimates to the target vertex.
ALT is quite popular and has also received research interest in areas beyond route planning.
However, query times are significantly slower than with shortcut-based approaches such as CH or MLD.
ALT has also been extended to dynamic and time-dependent settings~\cite{dn-crdtd-12}. % combined?
However, the model studied there is not as general as with customization based approaches.
% Core-ALT?
Another more recent A*-based approach is CH-Potentials~\cite{strasser_et_al:LIPIcs.SEA.2021.6}.
As the name suggests, CH-Potentials extract distance estimates from a CH which leads to tighter estimates and faster queries than with ALT.
For this, the Lazy RPHAST algorithm is introduced which we also heavily use in this work.
CH-Potentials can be applied to a variety of routing problem variants and the original publication even mentions a combination of live and predicted traffic.
However the reported query times are a above 100\,ms which we consider too slow for practical applications.

\subsection{Contribution}

In this work, we introduce a time-dependent generalization of A* potentials.
We then propose two efficient algorithms for such time-dependent A* potentials and discuss how to apply them to efficiently answer queries in a combined live and predicted traffic setting.
An extensive evaluation confirms the applicability of our algorithms.
Queries incorporating both predicted and the current traffic can usually be answered within few tenths of milliseconds.
Live-traffic updates can be integrated within less than a minute.
Compared to Dijkstra's algorithm, we achieve a speed-up of around two orders of magnitude and compared to a time-independent CH-Potential, we achieve a speed-up of up to an order of magnitude.
% Introduce A* with TDPot
% Introduce 2 TDPots
% Show how to apply them to live traffic
% Extensive eval
% up to one order of mag over time independent pot
% 2 orders of magnitude over dijkstra

\section{Preliminaries}
We consider directed graphs $G=(V,E)$ with $n=|V|$ vertices and $m=|E|$ edges.
We use $uv$ as a short notation for an edge from a \emph{tail} vertex $u$ to \emph{head} vertex $v$.
Each edge $e = uv \in E$ has a travel time function $\pred_e : \mathbb{Z} \to \mathbb{Z}^{\geq 0}$ which maps a departure time $\tau$ at $u$ to a predicted travel time $\pred_e(\tau)$.
The travel time of a path $P = (v_1,\dots,v_k)$ can be obtained by successively evaluating the edges travel times: $\pred_P(\tau) = \pred_{v_1 v_2}(\tau) + \pred_{(v_2,\dots,v_k)}(\tau + \pred_{v_1 v_2}(\tau))$.
In our implementation, travel time functions are periodic piecewise linear functions represented by a sequence of breakpoints covering one day of predictions.
We assume that all travel time functions adhere to the \emph{first-in first-out} (FIFO) property, i.e.\ departing later may never lead to an earlier arrival.
Formally stated this means $\tau + \pred(\tau) \leq \tau + \epsilon + \pred(\tau + \epsilon)$ for any $\epsilon \in \mathbb{Z}^{\geq 0}$.
% TODO explain waiting?
With non-FIFO travel time functions, the shortest path problem becomes \textsf{NP}-hard~\cite{or-tnp-89}.

% traffic model
Edges may further have a currently observed live travel time $w_e$ and a point in time $\tau_e^{\operatorname{end}}$ when we switch back to the predicted travel time.
We assume that the traffic predictions are a conservative estimate and that live-traffic will always have slower travel times due to accidents and other traffic incidents.
Thus, we define the combined travel time function of an edge as follows:
$\comb_e(\tau) = \max(\pred_e(\tau), \min(w_e, \pred_e(\tau_e^{\operatorname{end}}) + \tau_e^{\operatorname{end}} - \tau))$.
% TODO talk about -1 segment
% TODO visualize
% TODO inf

Our goal is given vertices $s$ and $t$ and an earliest departure $\tdep$ to obtain the path $P = (s,\dots,t)$ that minimizes $\comb_P(\tdep)$.
We refer to the travel time of this path as $\opttt(s,t,\tdep)$.

\subsection{Application Model}

% phases
We consider an application model with three phases.
During the first \emph{preprocessing} phase, the graph topology and traffic predictions are given.
A preprocessing algorithm may use these inputs to precompute auxiliary data which may take several hours.
In the second \emph{update} phase, traffic weights are given for the current moment $\tau^{\operatorname{now}}$ and should be incorporated into the precomputed data within as little time as possible.
This phase may be repeated frequently to adjust to the current state of traffic.
We do not call this phase \emph{customization} because we use customization algorithms from CCH and CATCHUp during both the preprocessing and the update phases.
During the third and final \emph{query} phase, many shortest path queries $(s,t,\tdep)$ where $\tdep \geq \tau^{\operatorname{now}}$ should be answered as quickly as possible.

\subsection{A*}
% feasibility
% lower-bound
\subsection{CCH}
% customizations
% CATCHUp?
\subsection{Lazy RPHAST}

\begin{algorithm2e}
\KwData{$\mathtt{D}^{\downarrow}[u]$: tentative distance from $u$ to $t$ computed by Dijkstra's algorithm on $\gchd$}
\KwData{$\mathtt{D}[u]$: memoized final distance from $u$ to $t$, initially $\bot$}
\SetKwFunction{Dist}{ComputeAndMemoizeDist}
\SetKwProg{Fn}{Function}{:}{}
\Fn{\Dist{$u$}}{
    \If{$\mathtt{D}[u] = \bot$}{
        $\mathtt{D}[u]\leftarrow \mathtt{D}^{\downarrow}[u]$\;
        \For{all arcs $uv$ in $\gchu$}{
            $d \leftarrow \Dist(v)$\;
            \If{$\mathtt{D}[u] < d + w(uv)$}{
                $\mathtt{D}[u] \leftarrow d + w(uv)$\;
                % $\mathtt{P}[u] \leftarrow v$\;
            }
        }
    }
    \Return{$\mathtt{D}[u]$}\;
}
\caption{Computing the distance from a single vertex $u$ to $t$ with Lazy RPHAST}
\label{algo:lazy_rphast}
\end{algorithm2e}

\section{Algorithms}

\subsection{Multi-Metric Potential}

We now introduce our first time-dependent potential, the \emph{Multi-Metric Potential}.
Let $(s,t,\tdep)$ be a query and $\tmax = \tdep + \opttt(s,t,\tdep)$ the optimal arrival at the target.
Consider any $\tau' \leq \tdep$, $\tau'' \geq \tmax$ and the weight function $l(e) = \min_{\tau' \leq \tau \leq \tau''}\pred_e(\tau)$.
Clearly, $\dist_{l}(v,t)$ provides lower bound estimates of distances to the target vertex during the time relevant for this query.
If $\tau'$ and $\tau''$ are close to $\tdep$ and $\tmax$ and if the difference between $\tau'$ and $\tau''$ is not too big, the estimates will be significantly tighter than global lower bound distances.
The \emph{Multi-Metric Potential} is based on this observation.
Instead of using a single potential based on a global lower bound valid for the entire time, we process multiple lower bound weight functions valid for different time intervals.
At query time, we then select an appropriate weight function.
Efficiently computing distances with respect to the selected weight function is done with the Lazy RPHAST.

\subparagraph{Preprocessing}
The very first step of the preprocessing for this potential is to perform the regular CCH preprocessing, i.e.\ compute a nested dissection order~\cite{ghuw-fbndocch-19} and construct the unweighted chordally completed augmented graph.
Now let $I$ be a set of time intervals.
In our implementation, we use 48 intervals of length 1\,h starting at each full and each half hour, 24 intervals of length 2\,h starting at each full hour, 12 intervals of length 4\,h starting every two hours, 6 intervals of length 8\,h starting every 4 hours, 4 intervals of length 12\,h starting every 6 hours and one interval covering the entire day.
During preprocessing, we extract lower bounds and run the CCH basic customization algorithm for each interval.
This can be trivially parallelized.
Also, the customization can be parallelized internally.
For further engineering details, we refer to~\cite{dsw-cch-15,bsw-rttau-19}.

\subparagraph{Update}
We compute an additional lower bound weight function of length 59\,minutes starting at $\tau^{\operatorname{now}}$ which incorporates the current live traffic situation.
Further, we extract an upper bound weight function for the entire day valid with respect to both the predicted and the live traffic.
We then run both the basic and the perfect customization algorithms for the upper bound without constructing a reduced augmented graph.
Recall that after the perfect customization, each edge in the CCH has the length of the shortest distance between its endpoints.
We now construct a reduced augmented graph for all lower bounds at once.
This graph contains all edges for which the customized global lower bound weight is not greater than the customized upper bound.
Edges where the upper bound now undercuts the global lower bound are removed in \emph{all} lower bound weights.
% could do for each weight seperately but not worth it
Finally, we construct the reduced graph for the upper bound by removing all edges which were improved during its perfect customization.
The running time of the update phase is dominated by the construction of the reduced graphs.
Parallelizing it is crucial to achieve good running times.
See~\cite{bsw-rttau-19} for engineering details.
Note that the graph reduction steps are entirely optional and only serve to optimize query performance.
In case update running times are critical, the graph reduction can be skipped which will slightly worsen the query performance.

\subparagraph{Query}
We perform a classical CCH query on the customized upper bound to obtain a pessimistic estimate of $\tmax$.
We then select the shortest lower bound interval which still fully includes $[\tdep,\tmax]$.
Running Lazy RPHAST on the customized weight function of this interval then yields the potential function.
% Metric switching

% Correctness

\subsection{Interval-Minimum Potential}

The \emph{Interval-Minimum Potential} is a time-dependent adaptation of the Lazy RPHAST algorithm.
Where Lazy RPHAST has a single scalar (lower bound) weight for each edge, the Interval-Minimum Potential has a lower bound function.
This allows for tighter lower bound estimates but introduces new challenges.
First, computing an augmented CH graph with time-dependent travel time functions (even with only approximated lower bound functions) is difficult problem on its own an has been subject to study for entire articles~\cite{bgsv-mtdtt-13,swz-sfert-21}.
We therefore utilize the existing CATCHUp algorithm~\cite{swz-sfert-21}.
Second, storing the travel time functions of an augmented graph can be very expensive in terms of memory consumption.
Also, the usual representation as a list of breakpoints makes the evaluation much more expensive than looking up a scalar weight.
We therefore resort to a different representation and store functions as piecewise constant values in buckets of equal time.
In our implementation, we split the day into 96 buckets of length 15 minutes.
Third, evaluating the lower bound functions requires a time of evaluation.
While we have a time for the vertex for which we compute the potential, Lazy RPHAST also needs a time for every recursive invocation.
We therefore apply Lazy RPHAST a second time on a global upper and lower bound weight function to obtain an arrival interval at each vertex.

\subparagraph{Preprocessing}
The first step is the same as for the Multi-Metric Potential: performing the CCH preprocessing.
Then, we perform a CATACHUp customization.
This yields tight scalar upper and lower bounds as well as time-dependent unpacking information which allows to reconstruct the path represented by a shortcut for each point in time.
The original CATCHUp customization algorithm does not output shortcut travel time functions.
However, approximated functions are maintained throughout the customization.
From these approximated functions, we extract the piecewise constant lower bound buckets for all edges in the augmented graph.

\subparagraph{Update}
As for the Multi-Metric Potential, we extract an upper bound weight function for the entire day valid with respect to both the predicted and the live traffic.
We then run both the basic and the perfect customization algorithms for the upper bound without constructing a reduced augmented graph.
Now, we remove all CCH edges, where the upper bound undercuts the scalar lower bound from the CATCHUp customization and prepare two graphs:
One with the bucket-based time-dependent lower bound functions and another one with the scalar upper and lower bounds.
The running time of this phase is again dominated by the construction of the reduced graphs and the adjustments discussed in the previous section are applicable, too.

% derive from sources when predicted upper bound valid again (this is the reason why not reduced in preprocessing)
% reduced graph bounds
% reduced graph buckets by predicted bounds
% bound switching

\subparagraph{Query}
For the query, we build the potential with two instantiations of the Lazy RPHAST algorithm.
The first one works on the graph with the scalar bounds and computes lower and upper bounds on the distance from the source vertex.
The second one works on the graph with the bucket-based time-dependent lower bound functions.
The second one uses the first one to determine arrival intervals at each vertex which are in turn used to evaluate outgoing edges.

Choosing the right memory layout for the bucket weights is crucial for the performance of this algorithm.
We do store all weights of a single bucket consecutively.
Typically, only few buckets per edge are relevant, because the arrival intervals are relatively tight.
Also, outgoing all edges of each vertex are evaluated consecutively.
Thus, having their weights for the same bucket close to each other increases cache hits.

% evaluation time metric pruning
% correctness

\subsection{Compression}

Both our time-dependent potentials have to store a significant number of weight functions.
This can lead to problematic memory consumption.
However, since we only need lower bounds, we can merge lower bound weight functions into a combined weight function with the respective minimum weights and thus reduce the number of weight functions we need to store.
Thus by trading some lower bound tightness, we can reduce memory consumption.
Dealing with merged lower bound functions can be implemented for both potentials with a layer of indirection which maps each bucket or interval to a weight function id.
Then, when merging to weight functions, we let both buckets/intervals point to the same weight function id.

We now discuss an efficient and well parallelizable algorithm to iteratively merge weight functions until only $k$ functions remain.
In each step, we merge the pair of weight functions with the minimal sum of squared differences over all edge weights.
Since comparing all weight function pairs is expensive, we track the minimum difference sum we have found so far and stop any comparison where the sum exceeds the best sum.
Even when stopping a comparison, we store the sum so far and the edge id up to which we have summed up the differences.
This allows to avoid repeating the work already performed should we need to continue to compare this particular pair of weight functions.
Finally, we maintain all pairs of weights along with the (possibly partial) difference sums in a priority queue ordered by the difference sums.
When merging two weight functions, all other associated queue entries are removed from the queue and new entries for comparisons between the new weight function and all other functions are inserted.
To determine the next weight function pair to merge, unfinished weight function pairs are popped from the queue and processed in parallel.
The minimum difference is tracked in an atomic variable.

\section{Evaluation}
% data
\section{Conclusion}

% \section{Typesetting instructions -- Summary}
% \label{sec:typesetting-summary}

% LIPIcs is a series of open access high-quality conference proceedings across all fields in informatics established in cooperation with Schloss Dagstuhl.
% In order to do justice to the high scientific quality of the conferences that publish their proceedings in the LIPIcs series, which is ensured by the thorough review process of the respective events, we believe that LIPIcs proceedings must have an attractive and consistent layout matching the standard of the series.
% Moreover, the quality of the metadata, the typesetting and the layout must also meet the requirements of other external parties such as indexing service, DOI registry, funding agencies, among others. The guidelines contained in this document serve as the baseline for the authors, editors, and the publisher to create documents that meet as many different requirements as possible.

% Please comply with the following instructions when preparing your article for a LIPIcs proceedings volume.
% \paragraph*{Minimum requirements}

% \begin{itemize}
% \item Use pdflatex and an up-to-date \LaTeX{} system.
% \item Use further \LaTeX{} packages and custom made macros carefully and only if required.
% \item Use the provided sectioning macros: \verb+\section+, \verb+\subsection+, \verb+\subsubsection+, \linebreak \verb+\paragraph+, \verb+\paragraph*+, and \verb+\subparagraph*+.
% \item Provide suitable graphics of at least 300dpi (preferably in PDF format).
% \item Use BibTeX and keep the standard style (\verb+plainurl+) for the bibliography.
% \item Please try to keep the warnings log as small as possible. Avoid overfull \verb+\hboxes+ and any kind of warnings/errors with the referenced BibTeX entries.
% \item Use a spellchecker to correct typos.
% \end{itemize}

% \paragraph*{Mandatory metadata macros}
% Please set the values of the metadata macros carefully since the information parsed from these macros will be passed to publication servers, catalogues and search engines.
% Avoid placing macros inside the metadata macros. The following metadata macros/environments are mandatory:
% \begin{itemize}
% \item \verb+\title+ and, in case of long titles, \verb+\titlerunning+.
% \item \verb+\author+, one for each author, even if two or more authors have the same affiliation.
% \item \verb+\authorrunning+ and \verb+\Copyright+ (concatenated author names)\\
% The \verb+\author+ macros and the \verb+\Copyright+ macro should contain full author names (especially with regard to the first name), while \verb+\authorrunning+ should contain abbreviated first names.
% \item \verb+\ccsdesc+ (ACM classification, see \url{https://www.acm.org/publications/class-2012}).
% \item \verb+\keywords+ (a comma-separated list of keywords).
% \item \verb+\relatedversion+ (if there is a related version, typically the ``full version''); please make sure to provide a persistent URL, e.\,g., at arXiv.
% \item \verb+\begin{abstract}...\end{abstract}+ .
% \end{itemize}

% \paragraph*{Please do not \ldots} %Do not override the \texttt{\seriesstyle}-defaults}
% Generally speaking, please do not override the \texttt{lipics-v2021}-style defaults. To be more specific, a short checklist also used by Dagstuhl Publishing during the final typesetting is given below.
% In case of \textbf{non-compliance} with these rules Dagstuhl Publishing will remove the corresponding parts of \LaTeX{} code and \textbf{replace it with the \texttt{lipics-v2021} defaults}. In serious cases, we may reject the LaTeX-source and expect the corresponding author to revise the relevant parts.
% \begin{itemize}
% \item Do not use a different main font. (For example, the \texttt{times} package is forbidden.)
% \item Do not alter the spacing of the \texttt{lipics-v2021.cls} style file.
% \item Do not use \verb+enumitem+ and \verb+paralist+. (The \texttt{enumerate} package is preloaded, so you can use
%  \verb+\begin{enumerate}[(a)]+ or the like.)
% \item Do not use ``self-made'' sectioning commands (e.\,g., \verb+\noindent{\bf My+ \verb+Paragraph}+).
% \item Do not hide large text blocks using comments or \verb+\iffalse+ $\ldots$ \verb+\fi+ constructions.
% \item Do not use conditional structures to include/exclude content. Instead, please provide only the content that should be published -- in one file -- and nothing else.
% \item Do not wrap figures and tables with text. In particular, the package \texttt{wrapfig} is not supported.
% \item Do not change the bibliography style. In particular, do not use author-year citations. (The
% \texttt{natbib} package is not supported.)
% \end{itemize}

% \enlargethispage{\baselineskip}

% This is only a summary containing the most relevant details. Please read the complete document ``LIPIcs: Instructions for Authors and the \texttt{lipics-v2021} Class'' for all details and don't hesitate to contact Dagstuhl Publishing (\url{mailto:publishing@dagstuhl.de}) in case of questions or comments:
% \href{http://drops.dagstuhl.de/styles/lipics-v2021/lipics-v2021-authors/lipics-v2021-authors-guidelines.pdf}{\texttt{http://drops.dagstuhl.de/styles/lipics-v2021/\newline lipics-v2021-authors/lipics-v2021-authors-guidelines.pdf}}

% \section{Lorem ipsum dolor sit amet}

% Lorem ipsum dolor sit amet, consectetur adipiscing elit \cite{DBLP:journals/cacm/Knuth74}. Praesent convallis orci arcu, eu mollis dolor. Aliquam eleifend suscipit lacinia. Maecenas quam mi, porta ut lacinia sed, convallis ac dui. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Suspendisse potenti. Donec eget odio et magna ullamcorper vehicula ut vitae libero. Maecenas lectus nulla, auctor nec varius ac, ultricies et turpis. Pellentesque id ante erat. In hac habitasse platea dictumst. Curabitur a scelerisque odio. Pellentesque elit risus, posuere quis elementum at, pellentesque ut diam. Quisque aliquam libero id mi imperdiet quis convallis turpis eleifend.

% \begin{lemma}[Lorem ipsum]
% \label{lemma:lorem}
% Vestibulum sodales dolor et dui cursus iaculis. Nullam ullamcorper purus vel turpis lobortis eu tempus lorem semper. Proin facilisis gravida rutrum. Etiam sed sollicitudin lorem. Proin pellentesque risus at elit hendrerit pharetra. Integer at turpis varius libero rhoncus fermentum vitae vitae metus.
% \end{lemma}

% \begin{proof}
% Cras purus lorem, pulvinar et fermentum sagittis, suscipit quis magna.


% \proofsubparagraph*{Just some paragraph within the proof.}
% Nam liber tempor cum soluta nobis eleifend option congue nihil imperdiet doming id quod mazim placerat facer possim assum. Lorem ipsum dolor sit amet, consectetuer adipiscing elit, sed diam nonummy nibh euismod tincidunt ut laoreet dolore magna aliquam erat volutpat.
% \begin{claim}
% content...
% \end{claim}
% \begin{claimproof}
% content...
%     \begin{enumerate}
%         \item abc abc abc \claimqedhere{}
%     \end{enumerate}
% \end{claimproof}

% \end{proof}

% \begin{corollary}[Curabitur pulvinar, \cite{DBLP:books/mk/GrayR93}]
% \label{lemma:curabitur}
% Nam liber tempor cum soluta nobis eleifend option congue nihil imperdiet doming id quod mazim placerat facer possim assum. Lorem ipsum dolor sit amet, consectetuer adipiscing elit, sed diam nonummy nibh euismod tincidunt ut laoreet dolore magna aliquam erat volutpat.
% \end{corollary}

% \begin{proposition}\label{prop1}
% This is a proposition
% \end{proposition}

% \autoref{prop1} and \cref{prop1} \ldots

% \subsection{Curabitur dictum felis id sapien}

% Curabitur dictum \cref{lemma:curabitur} felis id sapien \autoref{lemma:curabitur} mollis ut venenatis tortor feugiat. Curabitur sed velit diam. Integer aliquam, nunc ac egestas lacinia, nibh est vehicula nibh, ac auctor velit tellus non arcu. Vestibulum lacinia ipsum vitae nisi ultrices eget gravida turpis laoreet. Duis rutrum dapibus ornare. Nulla vehicula vulputate iaculis. Proin a consequat neque. Donec ut rutrum urna. Morbi scelerisque turpis sed elit sagittis eu scelerisque quam condimentum. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Aenean nec faucibus leo. Cras ut nisl odio, non tincidunt lorem. Integer purus ligula, venenatis et convallis lacinia, scelerisque at erat. Fusce risus libero, convallis at fermentum in, dignissim sed sem. Ut dapibus orci vitae nisl viverra nec adipiscing tortor condimentum \cite{DBLP:journals/cacm/Dijkstra68a}. Donec non suscipit lorem. Nam sit amet enim vitae nisl accumsan pretium.

% \begin{lstlisting}[caption={Useless code.},label=list:8-6,captionpos=t,float,abovecaptionskip=-\medskipamount]
% for i:=maxint to 0 do
% begin
%     j:=square(root(i));
% end;
% \end{lstlisting}

% \subsection{Proin ac fermentum augue}

% Proin ac fermentum augue. Nullam bibendum enim sollicitudin tellus egestas lacinia euismod orci mollis. Nulla facilisi. Vivamus volutpat venenatis sapien, vitae feugiat arcu fringilla ac. Mauris sapien tortor, sagittis eget auctor at, vulputate pharetra magna. Sed congue, dui nec vulputate convallis, sem nunc adipiscing dui, vel venenatis mauris sem in dui. Praesent a pretium quam. Mauris non mauris sit amet eros rutrum aliquam id ut sapien. Nulla aliquet fringilla sagittis. Pellentesque eu metus posuere nunc tincidunt dignissim in tempor dolor. Nulla cursus aliquet enim. Cras sapien risus, accumsan eu cursus ut, commodo vel velit. Praesent aliquet consectetur ligula, vitae iaculis ligula interdum vel. Integer faucibus faucibus felis.

% \begin{itemize}
% \item Ut vitae diam augue.
% \item Integer lacus ante, pellentesque sed sollicitudin et, pulvinar adipiscing sem.
% \item Maecenas facilisis, leo quis tincidunt egestas, magna ipsum condimentum orci, vitae facilisis nibh turpis et elit.
% \end{itemize}

% \begin{remark}
% content...
% \end{remark}

% \section{Pellentesque quis tortor}

% Nec urna malesuada sollicitudin. Nulla facilisi. Vivamus aliquam tempus ligula eget ornare. Praesent eget magna ut turpis mattis cursus. Aliquam vel condimentum orci. Nunc congue, libero in gravida convallis \cite{DBLP:conf/focs/HopcroftPV75}, orci nibh sodales quam, id egestas felis mi nec nisi. Suspendisse tincidunt, est ac vestibulum posuere, justo odio bibendum urna, rutrum bibendum dolor sem nec tellus.

% \begin{lemma} [Quisque blandit tempus nunc]
% Sed interdum nisl pretium non. Mauris sodales consequat risus vel consectetur. Aliquam erat volutpat. Nunc sed sapien ligula. Proin faucibus sapien luctus nisl feugiat convallis faucibus elit cursus. Nunc vestibulum nunc ac massa pretium pharetra. Nulla facilisis turpis id augue venenatis blandit. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus.
% \end{lemma}

% Fusce eu leo nisi. Cras eget orci neque, eleifend dapibus felis. Duis et leo dui. Nam vulputate, velit et laoreet porttitor, quam arcu facilisis dui, sed malesuada risus massa sit amet neque.

% \section{Morbi eros magna}

% Morbi eros magna, vestibulum non posuere non, porta eu quam. Maecenas vitae orci risus, eget imperdiet mauris. Donec massa mauris, pellentesque vel lobortis eu, molestie ac turpis. Sed condimentum convallis dolor, a dignissim est ultrices eu. Donec consectetur volutpat eros, et ornare dui ultricies id. Vivamus eu augue eget dolor euismod ultrices et sit amet nisi. Vivamus malesuada leo ac leo ullamcorper tempor. Donec justo mi, tempor vitae aliquet non, faucibus eu lacus. Donec dictum gravida neque, non porta turpis imperdiet eget. Curabitur quis euismod ligula.


%%
%% Bibliography
%%

%% Please use bibtex, 

\bibliography{references}

\appendix

% \section{Styles of lists, enumerations, and descriptions}\label{sec:itemStyles}

% List of different predefined enumeration styles:

% \begin{itemize}
% \item \verb|\begin{itemize}...\end{itemize}|
% \item \dots
% \item \dots
% %\item \dots
% \end{itemize}

% \begin{enumerate}
% \item \verb|\begin{enumerate}...\end{enumerate}|
% \item \dots
% \item \dots
% %\item \dots
% \end{enumerate}

% \begin{alphaenumerate}
% \item \verb|\begin{alphaenumerate}...\end{alphaenumerate}|
% \item \dots
% \item \dots
% %\item \dots
% \end{alphaenumerate}

% \begin{romanenumerate}
% \item \verb|\begin{romanenumerate}...\end{romanenumerate}|
% \item \dots
% \item \dots
% %\item \dots
% \end{romanenumerate}

% \begin{bracketenumerate}
% \item \verb|\begin{bracketenumerate}...\end{bracketenumerate}|
% \item \dots
% \item \dots
% %\item \dots
% \end{bracketenumerate}

% \begin{description}
% \item[Description 1] \verb|\begin{description} \item[Description 1]  ...\end{description}|
% \item[Description 2] Fusce eu leo nisi. Cras eget orci neque, eleifend dapibus felis. Duis et leo dui. Nam vulputate, velit et laoreet porttitor, quam arcu facilisis dui, sed malesuada risus massa sit amet neque.
% \item[Description 3]  \dots
% %\item \dots
% \end{description}

% \cref{testenv-proposition} and \autoref{testenv-proposition} ...

% \section{Theorem-like environments}\label{sec:theorem-environments}

% List of different predefined enumeration styles:

% \begin{theorem}\label{testenv-theorem}
% Fusce eu leo nisi. Cras eget orci neque, eleifend dapibus felis. Duis et leo dui. Nam vulputate, velit et laoreet porttitor, quam arcu facilisis dui, sed malesuada risus massa sit amet neque.
% \end{theorem}

% \begin{lemma}\label{testenv-lemma}
% Fusce eu leo nisi. Cras eget orci neque, eleifend dapibus felis. Duis et leo dui. Nam vulputate, velit et laoreet porttitor, quam arcu facilisis dui, sed malesuada risus massa sit amet neque.
% \end{lemma}

% \begin{corollary}\label{testenv-corollary}
% Fusce eu leo nisi. Cras eget orci neque, eleifend dapibus felis. Duis et leo dui. Nam vulputate, velit et laoreet porttitor, quam arcu facilisis dui, sed malesuada risus massa sit amet neque.
% \end{corollary}

% \begin{proposition}\label{testenv-proposition}
% Fusce eu leo nisi. Cras eget orci neque, eleifend dapibus felis. Duis et leo dui. Nam vulputate, velit et laoreet porttitor, quam arcu facilisis dui, sed malesuada risus massa sit amet neque.
% \end{proposition}

% \begin{conjecture}\label{testenv-conjecture}
% Fusce eu leo nisi. Cras eget orci neque, eleifend dapibus felis. Duis et leo dui. Nam vulputate, velit et laoreet porttitor, quam arcu facilisis dui, sed malesuada risus massa sit amet neque.
% \end{conjecture}

% \begin{observation}\label{testenv-observation}
% Fusce eu leo nisi. Cras eget orci neque, eleifend dapibus felis. Duis et leo dui. Nam vulputate, velit et laoreet porttitor, quam arcu facilisis dui, sed malesuada risus massa sit amet neque.
% \end{observation}

% \begin{exercise}\label{testenv-exercise}
% Fusce eu leo nisi. Cras eget orci neque, eleifend dapibus felis. Duis et leo dui. Nam vulputate, velit et laoreet porttitor, quam arcu facilisis dui, sed malesuada risus massa sit amet neque.
% \end{exercise}

% \begin{definition}\label{testenv-definition}
% Fusce eu leo nisi. Cras eget orci neque, eleifend dapibus felis. Duis et leo dui. Nam vulputate, velit et laoreet porttitor, quam arcu facilisis dui, sed malesuada risus massa sit amet neque.
% \end{definition}

% \begin{example}\label{testenv-example}
% Fusce eu leo nisi. Cras eget orci neque, eleifend dapibus felis. Duis et leo dui. Nam vulputate, velit et laoreet porttitor, quam arcu facilisis dui, sed malesuada risus massa sit amet neque.
% \end{example}

% \begin{note}\label{testenv-note}
% Fusce eu leo nisi. Cras eget orci neque, eleifend dapibus felis. Duis et leo dui. Nam vulputate, velit et laoreet porttitor, quam arcu facilisis dui, sed malesuada risus massa sit amet neque.
% \end{note}

% \begin{note*}
% Fusce eu leo nisi. Cras eget orci neque, eleifend dapibus felis. Duis et leo dui. Nam vulputate, velit et laoreet porttitor, quam arcu facilisis dui, sed malesuada risus massa sit amet neque.
% \end{note*}

% \begin{remark}\label{testenv-remark}
% Fusce eu leo nisi. Cras eget orci neque, eleifend dapibus felis. Duis et leo dui. Nam vulputate, velit et laoreet porttitor, quam arcu facilisis dui, sed malesuada risus massa sit amet neque.
% \end{remark}

% \begin{remark*}
% Fusce eu leo nisi. Cras eget orci neque, eleifend dapibus felis. Duis et leo dui. Nam vulputate, velit et laoreet porttitor, quam arcu facilisis dui, sed malesuada risus massa sit amet neque.
% \end{remark*}

% \begin{claim}\label{testenv-claim}
% Fusce eu leo nisi. Cras eget orci neque, eleifend dapibus felis. Duis et leo dui. Nam vulputate, velit et laoreet porttitor, quam arcu facilisis dui, sed malesuada risus massa sit amet neque.
% \end{claim}

% \begin{claim*}\label{testenv-claim2}
% Fusce eu leo nisi. Cras eget orci neque, eleifend dapibus felis. Duis et leo dui. Nam vulputate, velit et laoreet porttitor, quam arcu facilisis dui, sed malesuada risus massa sit amet neque.
% \end{claim*}

% \begin{proof}
% Fusce eu leo nisi. Cras eget orci neque, eleifend dapibus felis. Duis et leo dui. Nam vulputate, velit et laoreet porttitor, quam arcu facilisis dui, sed malesuada risus massa sit amet neque.
% \end{proof}

% \begin{claimproof}
% Fusce eu leo nisi. Cras eget orci neque, eleifend dapibus felis. Duis et leo dui. Nam vulputate, velit et laoreet porttitor, quam arcu facilisis dui, sed malesuada risus massa sit amet neque.
% \end{claimproof}

\end{document}
